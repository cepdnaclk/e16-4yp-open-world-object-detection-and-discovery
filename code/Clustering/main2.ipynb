{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crop_features import crop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image set created with shape  torch.Size([100, 3, 384, 600])\n",
      "Features created with shape torch.Size([100, 256, 96, 150])\n",
      "Number of objects obtained :  665\n"
     ]
    }
   ],
   "source": [
    "annotation_file = './datasets/t1_train/t1_train_coco.json'\n",
    "image_dir = './data/coco/images'\n",
    "objects_arr, class_arr, img_id_arr, bbox_arr = crop_features(annotation_file, image_dir, FH = 384, FW = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy of kmeans.py #updated\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from pykeops.torch import LazyTensor\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.float32 if use_cuda else torch.float64\n",
    "device_id = \"cuda:0\" if use_cuda else \"cpu\"\n",
    "\n",
    "\n",
    "def KMeans(x, K=10, Niter=10, verbose=True):\n",
    "    \"\"\"Implements Lloyd's algorithm for the Euclidean metric.\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    N, D = x.shape  # Number of samples, dimension of the ambient space\n",
    "\n",
    "    c = x[:K, :].clone()  # Simplistic initialization for the centroids\n",
    "\n",
    "    x_i = LazyTensor(x.view(N, 1, D))  # (N, 1, D) samples\n",
    "    c_j = LazyTensor(c.view(1, K, D))  # (1, K, D) centroids\n",
    "\n",
    "    # K-means loop:\n",
    "    # - x  is the (N, D) point cloud,\n",
    "    # - cl is the (N,) vector of class labels\n",
    "    # - c  is the (K, D) cloud of cluster centroids\n",
    "    for i in range(Niter):\n",
    "\n",
    "        # E step: assign points to the closest cluster -------------------------\n",
    "        D_ij = ((x_i - c_j) ** 2).sum(-1)  # (N, K) symbolic squared distances\n",
    "        cl = D_ij.argmin(dim=1).long().view(-1)  # Points -> Nearest cluster\n",
    "\n",
    "        # M step: update the centroids to the normalized cluster average: ------\n",
    "        # Compute the sum of points per cluster:\n",
    "        c.zero_()\n",
    "        c.scatter_add_(0, cl[:, None].repeat(1, D), x)\n",
    "\n",
    "        # Divide by the number of points per cluster:\n",
    "        Ncl = torch.bincount(cl, minlength=K).type_as(c).view(K, 1)\n",
    "        c /= Ncl  # in-place division to compute the average\n",
    "\n",
    "    if verbose:  # Fancy display -----------------------------------------------\n",
    "        if use_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        print(\n",
    "            f\"K-means for the Euclidean metric with {N:,} points in dimension {D:,}, K = {K:,}:\"\n",
    "        )\n",
    "        print(\n",
    "            \"Timing for {} iterations: {:.5f}s = {} x {:.5f}s\\n\".format(\n",
    "                Niter, end - start, Niter, (end - start) / Niter\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return cl, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy of cluster.py part 1 #updated\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mode\n",
    "\n",
    "#get the class name of a given object class id\n",
    "def get_class_name(class_id, annotation_file):\n",
    "    \n",
    "    import json\n",
    "    with open(annotation_file, 'r') as file:\n",
    "        _data = json.load(file)\n",
    "        _classes = _data[\"categories\"]\n",
    "\n",
    "        for category in _classes:\n",
    "            if(category[\"id\"] == class_id):\n",
    "                return category[\"name\"]\n",
    "\n",
    "#get a dictionary with all object class ids and their names\n",
    "def get_all_class_names(class_arr, annotation_file):\n",
    "\n",
    "    classes = set(class_arr)\n",
    "    all_class_names = {}\n",
    "\n",
    "    for i in list(classes):\n",
    "        cls_name = get_class_name(i, annotation_file)\n",
    "        all_class_names[i] = cls_name\n",
    "    return all_class_names\n",
    "\n",
    "\n",
    "#get cluster names for the predicted kmeans cluster labels\n",
    "def get_cluster_names(class_arr, label, all_class_names):\n",
    "    clusters = {}\n",
    "    for i in range(len(label)):\n",
    "        cluster_id = label[i]\n",
    "        cluster_name = all_class_names[class_arr[i]]\n",
    "        \n",
    "        if cluster_id not in clusters.keys():\n",
    "            clusters[cluster_id] = []\n",
    "            pass\n",
    "        clusters[cluster_id].append(cluster_name)\n",
    "\n",
    "    cluster_names = {}\n",
    "    for i in clusters.keys():\n",
    "        cluster_names[i] = mode(clusters[i])\n",
    "    return cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means for the Euclidean metric with 665 points in dimension 256, K = 10:\n",
      "Timing for 10 iterations: 0.01546s = 10 x 0.00155s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#update for cluster.py part 2 (pred_clusters functions)\n",
    "data = np.array([x.numpy() for x in objects_arr], dtype=np.float32)\n",
    "x = torch.from_numpy(data)\n",
    "cl, c = KMeans(x, K=10, Niter=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([665])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owdetr2",
   "language": "python",
   "name": "owdetr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e47399d361540ecc2b8d37d81c198495adbc7792991885da0aa7392e2efe7225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
